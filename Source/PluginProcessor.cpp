/*
==============================================================================

This file was auto-generated by the Introjucer!

It contains the basic framework code for a JUCE plugin processor.

==============================================================================
*/

#include "PluginProcessor.h"
#include "PluginEditor.h"
#include <string.h>

//==============================================================================
ConvolutionReverbAudioProcessor::ConvolutionReverbAudioProcessor() : m_knob1(0),
m_knob2(0),
m_knob3(0),
m_knob4(0),
m_knob5(0)
{
	m_fFeedback = 0;
	m_fWetLevel = 0;
	m_fGain = 0;

	m_fGain = m_knob1;
	m_fDelayTime = m_knob2;
	m_fFeedback = m_knob3;
	m_fReverbTime = m_knob4;
	m_fWetLevel = m_knob5;

	PDelayL = PreDelay();
	PDelayL.setMaxDelay(m_sampleRate, 0.5);
	PDelayL.setDelayTime(m_sampleRate, m_fDelayTime);
	PDelayL.setWetMix(m_fWetLevel);
	PDelayL.setGainLevel(m_fGain);
	PDelayL.setFeedback(m_fFeedback);
	PDelayL.setPlayheads();

	PDelayR = PreDelay();
	PDelayR.setMaxDelay(m_sampleRate, 0.5);
	PDelayR.setDelayTime(m_sampleRate, m_fDelayTime);
	PDelayR.setWetMix(m_fWetLevel);
	PDelayR.setGainLevel(m_fGain);
	PDelayR.setFeedback(m_fFeedback);
	PDelayR.setPlayheads();
    
    formatManager.registerBasicFormats();
}

ConvolutionReverbAudioProcessor::~ConvolutionReverbAudioProcessor()
{
}


//==============================================================================
const String ConvolutionReverbAudioProcessor::getName() const
{
	return JucePlugin_Name;
}

int ConvolutionReverbAudioProcessor::getNumParameters()
{
	return totalNumParams;
}

float ConvolutionReverbAudioProcessor::getParameter(int index)
{
	switch (index) {
	case knob1Param: return m_knob1;
	case knob2Param: return m_knob2;
	case knob3Param: return m_knob3;
	case knob4Param: return m_knob4;
	case knob5Param: return m_knob5;
	default: return 0.0;
	}
}

void ConvolutionReverbAudioProcessor::setParameter(int index, float newValue)
{
	switch (index) {
		//Gain Knob
	case knob1Param: m_knob1 = newValue;
		m_fGain = m_knob1; 

		PDelayL.setGainLevel(m_fGain);
		PDelayR.setGainLevel(m_fGain);break;

		//Delay Time Knob
	case knob2Param: m_knob2 = newValue;
		m_fDelayTime = m_knob2;

		PDelayL.setDelayTime(m_sampleRate, m_fDelayTime);
		PDelayL.setPlayheads();

		PDelayR.setDelayTime(m_sampleRate, m_fDelayTime);
		PDelayR.setPlayheads(); break;

		//Feedback Knob
	case knob3Param: m_knob3 = newValue;
		m_fFeedback = m_knob3;

		PDelayL.setFeedback(m_fFeedback);
		PDelayR.setFeedback(m_fFeedback); break;

		//Reverb Time Knob
	case knob4Param: m_knob4 = newValue;
		m_fReverbTime = m_knob4; break;

		//Mix Knob
	case knob5Param: m_knob5 = wet = newValue;
        m_fWetLevel = m_knob5;
            
		PDelayL.setWetMix(m_fWetLevel);
		PDelayR.setWetMix(m_fWetLevel); break;

	default: break;
	}
}

const String ConvolutionReverbAudioProcessor::getParameterName(int index)
{
	switch (index){
	case knob1Param: return "Gain";
	case knob2Param: return "Delay Time";
	case knob3Param: return "Feedback";
	case knob4Param: return "Reverb Time";
	case knob5Param: return "Wet / Dry Mix";
	default: return String::empty;
	}
}

const String ConvolutionReverbAudioProcessor::getParameterText(int index)
{
	return String(getParameter(index), 2);
}

const String ConvolutionReverbAudioProcessor::getInputChannelName(int channelIndex) const
{
	return String(channelIndex + 1);
}

const String ConvolutionReverbAudioProcessor::getOutputChannelName(int channelIndex) const
{
	return String(channelIndex + 1);
}

bool ConvolutionReverbAudioProcessor::isInputChannelStereoPair(int index) const
{
	return true;
}

bool ConvolutionReverbAudioProcessor::isOutputChannelStereoPair(int index) const
{
	return true;
}

bool ConvolutionReverbAudioProcessor::acceptsMidi() const
{
#if JucePlugin_WantsMidiInput
	return true;
#else
	return false;
#endif
}

bool ConvolutionReverbAudioProcessor::producesMidi() const
{
#if JucePlugin_ProducesMidiOutput
	return true;
#else
	return false;
#endif
}

bool ConvolutionReverbAudioProcessor::silenceInProducesSilenceOut() const
{
	return false;
}

double ConvolutionReverbAudioProcessor::getTailLengthSeconds() const
{
	return 0.0;
}

int ConvolutionReverbAudioProcessor::getNumPrograms()
{
	return 1;   // NB: some hosts don't cope very well if you tell them there are 0 programs,
	// so this should be at least 1, even if you're not really implementing programs.
}

int ConvolutionReverbAudioProcessor::getCurrentProgram()
{
	return 0;
}

void ConvolutionReverbAudioProcessor::setCurrentProgram(int index)
{
}

const String ConvolutionReverbAudioProcessor::getProgramName(int index)
{
	return String();
}

void ConvolutionReverbAudioProcessor::changeProgramName(int index, const String& newName)
{
}

void ConvolutionReverbAudioProcessor::buttonClicked()
{
    FileChooser chooser ("Select a Wave file shorter than 2 seconds to play...",
                         File::nonexistent,
                         "*.wav");
    
    if (chooser.browseForFileToOpen()){
        const File file (chooser.getResult());
        ScopedPointer<AudioFormatReader> reader (formatManager.createReaderFor (file));
        
        if (reader != nullptr){
            fileBuffer.setSize (2, reader->lengthInSamples);
            reader->read (&fileBuffer,
                            0,
                            reader->lengthInSamples,
                            0,
                            true,
                            true);
        }
    }
}

//==============================================================================
void ConvolutionReverbAudioProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
	m_sampleRate = sampleRate;
	m_fGain = m_knob1;
	m_fDelayTime = m_knob2;
	m_fFeedback = m_knob3;
	m_fReverbTime = m_knob4;
	m_fWetLevel = m_knob5;

	PDelayL.setMaxDelay(m_sampleRate, 0.5);
	PDelayL.setDelayTime(m_sampleRate, m_fDelayTime);
	PDelayL.setWetMix(m_fWetLevel);
	PDelayL.setGainLevel(m_fGain);
	PDelayL.setFeedback(m_fFeedback);
	PDelayL.prepareToPlay();
	PDelayL.setPlayheads();

	PDelayR.setMaxDelay(m_sampleRate, 0.5);
	PDelayR.setDelayTime(m_sampleRate, m_fDelayTime);
	PDelayR.setWetMix(m_fWetLevel);
	PDelayR.setGainLevel(m_fGain);
	PDelayR.setFeedback(m_fFeedback);
	PDelayR.prepareToPlay();
	PDelayR.setPlayheads();
    
    formatManager.registerBasicFormats();
    
    nbFilters = 2 ;
    
    nfft=samplesPerBlock *2;
    
    olaBuffer = new float*[nbFilters] ;
    for (int k=0; k<nbFilters; k++) {
        olaBuffer[k] = new float[nfft];
        for (int i=0; i<nfft; i++) {
            olaBuffer[k][i] = 0;
        }
    }
    
    dryBufferSize = samplesPerBlock;
    dryBuffer = new float[dryBufferSize];
    
    for (int i=0 ; i<dryBufferSize ; i++) {
        dryBuffer[i] = 0.0 ;
    }
    
    // Complex buffers for FFT
    impulse = (fftw_complex*)fftw_malloc(sizeof(fftw_complex) * nfft);
    data = (fftw_complex*)fftw_malloc(sizeof(fftw_complex) * nfft);
    result = (fftw_complex*)fftw_malloc(sizeof(fftw_complex) * nfft);
    
    // Forward and Backward FFT
    pImp = fftw_plan_dft_1d(nfft, impulse, impulse, FFTW_FORWARD, FFTW_ESTIMATE);
    pSig = fftw_plan_dft_1d(nfft, data, data, FFTW_FORWARD, FFTW_ESTIMATE);
    pOut = fftw_plan_dft_1d(nfft, result, result, FFTW_BACKWARD, FFTW_ESTIMATE);
    
    if(fileBuffer.getNumSamples() != 0.0){
        for (int channel = 0; channel < fileBuffer.getNumChannels(); ++channel){
            float* impulseData = fileBuffer.getWritePointer (channel);
            for (int i = 0; i < nfft; i++){
                if (i < fileBuffer.getNumSamples())
                    impulse[i][channel] = impulseData[i];
                else
                    impulse[i][channel] = 0.0;
            }
        }
        fftw_execute(pImp);
    }
    oldwet = wet ;
}

void ConvolutionReverbAudioProcessor::releaseResources()
{
	// When playback stops, you can use this as an opportunity to free up any
	// spare memory, etc.
    delete [] dryBuffer ;
    
    for (int k = 0; k < nbFilters; k++)
        delete [] olaBuffer[k];
    delete [] olaBuffer;
    
    fftw_destroy_plan(pSig);
    fftw_destroy_plan(pImp);
    fftw_destroy_plan(pOut);
    fftw_free(data);
    fftw_free(impulse);
    fftw_free(result);
}

void ConvolutionReverbAudioProcessor::processBlock(AudioSampleBuffer& buffer, MidiBuffer& midiMessages)
{
    const int totalNumInputChannels  = getTotalNumInputChannels();
    int N = getTotalNumOutputChannels();
    int bufsize = buffer.getNumSamples();
    
    for (int channel = 0; channel < totalNumInputChannels; ++channel){
        float* channelData = buffer.getWritePointer(channel);
        
        for(int n=0;n<buffer.getNumSamples(); ++n){
            if(channel == 0)
                channelData[n] = PDelayL.process(channelData[n]);
                
            else if(channel == 1)
                channelData[n] = PDelayR.process(channelData[n]);
            }
        }
    
    if(fileBuffer.getNumSamples() != 0.0){
        /*for (int i = 0; i<dryBufferSize-bufsize; i++){
            dryBuffer[i] = dryBuffer[i+bufsize];
        }
        for (int channel = 0; channel < totalNumInputChannels; ++channel){
            float* channelData = buffer.getWritePointer(channel);
            for (int i = 0; i < bufsize; i++){
                dryBuffer[i] = channelData[i];
            }
        }*/
            
        for (int channel = 0; channel < totalNumInputChannels; ++channel){
            float* channelData = buffer.getWritePointer(channel);
            for (int i = 0; i < nfft; i++){
                if (i < bufsize)
                    data[i][channel] = channelData[i];
                else
                    data[i][channel] = 0.0;
            }
        }
            
        fftw_execute(pSig);

        for (int i = 0; i < nfft; i++){
            result[i][0] = data[i][0] * impulse[i][0] - data[i][1] * impulse[i][1];
            result[i][1] = data[i][0] * impulse[i][1] + data[i][1] * impulse[i][0];
        }
            
        fftw_execute(pOut);
            
        for (int k=0; k<nbFilters; k++) {
            for (int i = 0; i<nfft-bufsize; i++){
                olaBuffer[k][i] = olaBuffer[k][i+bufsize];
            }
            for (int i = (nfft-bufsize); i<nfft; i++){
                olaBuffer[k][i] = 0.0;
            }
        }
            
        for (int channel = 0; channel < totalNumInputChannels; ++channel){
            for (int i = 0; i<nfft; i++) {
                olaBuffer[channel][i] = result[i][channel];
            }
        }
            
        /*for (int i = 0; i < N ; ++i) {
            buffer.clear (i, 0, bufsize) ;
        }*/
            
        for (int channel = 0; channel < totalNumInputChannels; ++channel){
            float* channelData = buffer.getWritePointer(channel);
            for (int i = 0; i < nfft; i++){
                channelData[i] += olaBuffer[channel][i];
            }
        }
        
        /*
        buffer.addFromWithRamp(0, 0, olaBuffer[0], bufsize, oldwet, wet); // wet signal
        buffer.addFromWithRamp(0, 0, dryBuffer, bufsize, (1.0-oldwet), (1.0-wet)); // dry signal
        
        buffer.addFromWithRamp(1, 0, olaBuffer[1], bufsize, oldwet, wet); // wet signal
        buffer.addFromWithRamp(1, 0, dryBuffer, bufsize, (1.0-oldwet), (1.0-wet)); // dry signal
        */
        oldwet = wet;
    }
}

//==============================================================================
bool ConvolutionReverbAudioProcessor::hasEditor() const
{
	return true; // (change this to false if you choose to not supply an editor)
}

AudioProcessorEditor* ConvolutionReverbAudioProcessor::createEditor()
{
	return new ConvolutionReverbAudioProcessorEditor(*this);
}

//==============================================================================
void ConvolutionReverbAudioProcessor::getStateInformation(MemoryBlock& destData)
{
	// You should use this method to store your parameters in the memory block.
	// You could do that either as raw data, or use the XML or ValueTree classes
	// as intermediaries to make it easy to save and load complex data.
}

void ConvolutionReverbAudioProcessor::setStateInformation(const void* data, int sizeInBytes)
{
	// You should use this method to restore your parameters from this memory block,
	// whose contents will have been created by the getStateInformation() call.
}

//==============================================================================
// This creates new instances of the plugin..
AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
	return new ConvolutionReverbAudioProcessor();
}
