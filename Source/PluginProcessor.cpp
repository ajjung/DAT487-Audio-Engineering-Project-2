/*
==============================================================================

This file was auto-generated by the Introjucer!

It contains the basic framework code for a JUCE plugin processor.

==============================================================================
*/

#include "PluginProcessor.h"
#include "PluginEditor.h"
#include <string.h>

//==============================================================================
ConvolutionReverbAudioProcessor::ConvolutionReverbAudioProcessor() : m_knob1(0),
m_knob2(0),
m_knob3(0),
m_knob4(0),
m_knob5(0)
{
    fft = NULL;
    
	m_fFeedback = 0;
	m_fWetLevel = 0;
	m_fGain = 0;

	m_fGain = m_knob1;
	m_fDelayTime = m_knob2;
	m_fFeedback = m_knob3;
	m_fReverbTime = m_knob4;
	m_fWetLevel = m_knob5;

	PDelayL = PreDelay();
	PDelayL.setMaxDelay(m_sampleRate, 0.500);
	PDelayL.setDelayTime(m_sampleRate, m_fDelayTime);
	PDelayL.setWetMix(m_fWetLevel);
	PDelayL.setGainLevel(m_fGain);
	PDelayL.setFeedback(m_fFeedback);
	PDelayL.setPlayheads();

	PDelayR = PreDelay();
	PDelayR.setMaxDelay(m_sampleRate, 0.500);
	PDelayR.setDelayTime(m_sampleRate, m_fDelayTime);
	PDelayR.setWetMix(m_fWetLevel);
	PDelayR.setGainLevel(m_fGain);
	PDelayR.setFeedback(m_fFeedback);
	PDelayR.setPlayheads();
    
    formatManager.registerBasicFormats();
}

ConvolutionReverbAudioProcessor::~ConvolutionReverbAudioProcessor()
{
}


//==============================================================================
const String ConvolutionReverbAudioProcessor::getName() const
{
	return JucePlugin_Name;
}

int ConvolutionReverbAudioProcessor::getNumParameters()
{
	return totalNumParams;
}

float ConvolutionReverbAudioProcessor::getParameter(int index)
{
	switch (index) {
	case knob1Param: return m_knob1;
	case knob2Param: return m_knob2;
	case knob3Param: return m_knob3;
	case knob4Param: return m_knob4;
	case knob5Param: return m_knob5;
	default: return 0.0;
	}
}

void ConvolutionReverbAudioProcessor::setParameter(int index, float newValue)
{
	switch (index) {
		//Gain Knob
	case knob1Param: m_knob1 = newValue;
		m_fGain = m_knob1; 

		PDelayL.setGainLevel(m_fGain);
		PDelayR.setGainLevel(m_fGain);break;

		//Delay Time Knob
	case knob2Param: m_knob2 = newValue;
		m_fDelayTime = m_knob2;

		PDelayL.setDelayTime(m_sampleRate, m_fDelayTime);
		PDelayL.setPlayheads();

		PDelayR.setDelayTime(m_sampleRate, m_fDelayTime);
		PDelayR.setPlayheads(); break;

		//Feedback Knob
	case knob3Param: m_knob3 = newValue;
		m_fFeedback = m_knob3;

		PDelayL.setFeedback(m_fFeedback);
		PDelayR.setFeedback(m_fFeedback); break;

		//Reverb Time Knob
	case knob4Param: m_knob4 = newValue;
		m_fReverbTime = m_knob4; break;

		//Mix Knob
	case knob5Param: m_knob5 = newValue;
        m_fWetLevel = m_knob5;
            
		PDelayL.setWetMix(m_fWetLevel);
		PDelayR.setWetMix(m_fWetLevel); break;

	default: break;
	}
}

const String ConvolutionReverbAudioProcessor::getParameterName(int index)
{
	switch (index){
	case knob1Param: return "Gain";
	case knob2Param: return "Delay Time";
	case knob3Param: return "Feedback";
	case knob4Param: return "Reverb Time";
	case knob5Param: return "Wet / Dry Mix";
	default: return String::empty;
	}
}

const String ConvolutionReverbAudioProcessor::getParameterText(int index)
{
	return String(getParameter(index), 2);
}

const String ConvolutionReverbAudioProcessor::getInputChannelName(int channelIndex) const
{
	return String(channelIndex + 1);
}

const String ConvolutionReverbAudioProcessor::getOutputChannelName(int channelIndex) const
{
	return String(channelIndex + 1);
}

bool ConvolutionReverbAudioProcessor::isInputChannelStereoPair(int index) const
{
	return true;
}

bool ConvolutionReverbAudioProcessor::isOutputChannelStereoPair(int index) const
{
	return true;
}

bool ConvolutionReverbAudioProcessor::acceptsMidi() const
{
#if JucePlugin_WantsMidiInput
	return true;
#else
	return false;
#endif
}

bool ConvolutionReverbAudioProcessor::producesMidi() const
{
#if JucePlugin_ProducesMidiOutput
	return true;
#else
	return false;
#endif
}

bool ConvolutionReverbAudioProcessor::silenceInProducesSilenceOut() const
{
	return false;
}

double ConvolutionReverbAudioProcessor::getTailLengthSeconds() const
{
	return 0.0;
}

int ConvolutionReverbAudioProcessor::getNumPrograms()
{
	return 1;   // NB: some hosts don't cope very well if you tell them there are 0 programs,
	// so this should be at least 1, even if you're not really implementing programs.
}

int ConvolutionReverbAudioProcessor::getCurrentProgram()
{
	return 0;
}

void ConvolutionReverbAudioProcessor::setCurrentProgram(int index)
{
}

const String ConvolutionReverbAudioProcessor::getProgramName(int index)
{
	return String();
}

void ConvolutionReverbAudioProcessor::changeProgramName(int index, const String& newName)
{
}

void ConvolutionReverbAudioProcessor::buttonClicked()
{
    FileChooser chooser ("Select a Wave file shorter than 2 seconds to play...",
                         File::nonexistent,
                         "*.wav");
    
    if (chooser.browseForFileToOpen()){
        const File file (chooser.getResult());
        ScopedPointer<AudioFormatReader> reader (formatManager.createReaderFor (file));
        
        if (reader != nullptr)
        {
            fileBuffer.setSize (2, reader->lengthInSamples);      // [4]
            reader->read (&fileBuffer,                                              // [5]
                        0,                                                        //  [5.1]
                        reader->lengthInSamples,                                  //  [5.2]
                        0,                                                        //  [5.3]
                        true,                                                     //  [5.4]
                        true);                                                    //  [5.5]
        }
    }
}

//==============================================================================
void ConvolutionReverbAudioProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
	m_sampleRate = sampleRate;
	m_fGain = m_knob1;
	m_fDelayTime = m_knob2;
	m_fFeedback = m_knob3;
	m_fReverbTime = m_knob4;
	m_fWetLevel = m_knob5;

	PDelayL.setMaxDelay(m_sampleRate, 0.500);
	PDelayL.setDelayTime(m_sampleRate, m_fDelayTime);
	PDelayL.setWetMix(m_fWetLevel);
	PDelayL.setGainLevel(m_fGain);
	PDelayL.setFeedback(m_fFeedback);
	PDelayL.prepareToPlay();
	PDelayL.setPlayheads();

	PDelayR.setMaxDelay(m_sampleRate, 0.500);
	PDelayR.setDelayTime(m_sampleRate, m_fDelayTime);
	PDelayR.setWetMix(m_fWetLevel);
	PDelayR.setGainLevel(m_fGain);
	PDelayR.setFeedback(m_fFeedback);
	PDelayR.prepareToPlay();
	PDelayR.setPlayheads();
    
    formatManager.registerBasicFormats();
    
    nfft=samplesPerBlock * 2;
    
    if(fft == NULL)
        new FFTConvolver(nfft);
    
    olaBuffer = new float*[2] ;
    for (int k=0; k<2; k++) {
        olaBuffer[k] = new float[nfft];
        for (int i=0; i<nfft; i++) {
            olaBuffer[k][i] = 0;
        }
    }
    
    dryBuffer = new float[nfft];
    for (int i=0 ; i<nfft ; i++) {
        dryBuffer[i] = 0.0 ;
    }
        
    // Complex buffers for FFT
    impulse = (fftw_complex*)fftw_malloc(sizeof(fftw_complex) * nfft);
    data = (fftw_complex*)fftw_malloc(sizeof(fftw_complex) * nfft);
    result = (fftw_complex*)fftw_malloc(sizeof(fftw_complex) * nfft);
    
    //Forward and Backward FFT
    pImp = fftw_plan_dft_1d(nfft, impulse, impulse, FFTW_FORWARD, FFTW_ESTIMATE);
    pSig = fftw_plan_dft_1d(nfft, data, data, FFTW_FORWARD, FFTW_ESTIMATE);
    pOut = fftw_plan_dft_1d(nfft, result, result, FFTW_BACKWARD, FFTW_ESTIMATE);
    
    oldwet = wet ;
}

void ConvolutionReverbAudioProcessor::releaseResources()
{
	// When playback stops, you can use this as an opportunity to free up any
	// spare memory, etc.
    delete [] dryBuffer ;
    for (int k = 0; k < 2; k++)
        delete [] olaBuffer[k];
    delete [] olaBuffer;
    
    fftw_destroy_plan(pSig);
    fftw_destroy_plan(pImp);
    fftw_destroy_plan(pOut);
    fftw_free(data);
    fftw_free(impulse);
    fftw_free(result);
}

void ConvolutionReverbAudioProcessor::processBlock(AudioSampleBuffer& buffer, MidiBuffer& midiMessages)
{
    const int totalNumInputChannels  = getTotalNumInputChannels();
    int N = getTotalNumOutputChannels();
    int bufsize = buffer.getNumSamples();
    
    for (int channel = 0; channel < totalNumInputChannels; ++channel){
        float* channelData = buffer.getWritePointer(channel);
		float* impulseData = fileBuffer.getWritePointer(channel);

        for(int n=0;n<buffer.getNumSamples(); ++n){
            if(channel == 0)
                channelData[n] = PDelayL.process(channelData[n]);
                
            else if(channel == 1)
                channelData[n] = PDelayR.process(channelData[n]);
        }
    
        if(fileBuffer.getNumSamples() != 0.0)
        {
            /*olaBuffer = new float*[2] ;
            for (int k=0; k<2; k++) {
                olaBuffer[k] = new float[nfft];
                for (int i=0; i<nfft; i++) {
                    olaBuffer[k][i] = 0;
                }
            }
            
            dryBuffer = new float[dryBufferSize];
            for (int i=0 ; i<dryBufferSize ; i++) {
                dryBuffer[i] = 0.0 ;

			for (int i = 0; i < bufsize; i++)
				dryBuffer[i] = channelData[i];
            }
            */
            for (int i = 0; i<nfft-bufsize; i++)
                dryBuffer[i] = dryBuffer[i+bufsize];
        
            for (int i = (nfft-bufsize); i < nfft; i++)
                dryBuffer[i] = channelData[i-nfft+bufsize];
            
			for (int k = 0; k<2; k++){
				for (int i = 0; i<nfft - bufsize; i++)
					olaBuffer[k][i] = olaBuffer[k][i + bufsize];

				for (int i = (nfft - bufsize); i<nfft; i++)
					olaBuffer[k][i] = 0.0;
			}

            for (int i = 0; i < nfft; i++){
                if (i < bufsize)
                    data[i][0] = channelData[i];
                else
                    data[i][0] = 0.0;
            }
            
			for (int i = 0; i < nfft; i++){
				if (i < fileBuffer.getNumSamples())
					impulse[i][0] = impulseData[i];
				else
					impulse[i][0] = 0.0;
			}

			fftw_execute(pImp);

            fftw_execute(pSig);
            
            result[0][0] = data[0][0] * impulse[0][0];
            result[0][1] = data[0][1] * impulse[0][1];
            for(int i = 1; i < nfft; i++) {
                result[i][0] = data[i][0] * impulse[i][0] - data[i][1] * impulse[i][1];
                result[i][1] = data[i][0] * impulse[i][1] + data[i][1] * impulse[i][0];
            }
            
            fftw_execute(pOut);
            
            for (int i = 0; i < nfft; i++)
                olaBuffer[channel][i] += result[i][0];
            
            
            buffer.clear(0, 0, bufsize);
            buffer.clear(1, 0, bufsize);
            
            buffer.addFromWithRamp(0, 0, olaBuffer[0], bufsize, 0, 0); // wet signal
            buffer.addFromWithRamp(0, 0, dryBuffer, bufsize, 1, 1); // dry signal
             
            buffer.addFromWithRamp(1, 0, olaBuffer[1], bufsize, 0, 0); // wet signal
            buffer.addFromWithRamp(1, 0, dryBuffer, bufsize, 1, 1); // dry signal
            
            oldwet = wet;
        }
    }
}

//==============================================================================
bool ConvolutionReverbAudioProcessor::hasEditor() const
{
	return true; // (change this to false if you choose to not supply an editor)
}

AudioProcessorEditor* ConvolutionReverbAudioProcessor::createEditor()
{
	return new ConvolutionReverbAudioProcessorEditor(*this);
}

//==============================================================================
void ConvolutionReverbAudioProcessor::getStateInformation(MemoryBlock& destData)
{
	// You should use this method to store your parameters in the memory block.
	// You could do that either as raw data, or use the XML or ValueTree classes
	// as intermediaries to make it easy to save and load complex data.
}

void ConvolutionReverbAudioProcessor::setStateInformation(const void* data, int sizeInBytes)
{
	// You should use this method to restore your parameters from this memory block,
	// whose contents will have been created by the getStateInformation() call.
}

//==============================================================================
// This creates new instances of the plugin..
AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
	return new ConvolutionReverbAudioProcessor();
}
